# g2-lstm
Codes for "Towards Binary-Valued Gates for Robust LSTM Training".

Language modeling code is based on [awd-lstm-lm](https://github.com/salesforce/awd-lstm-lm) using PyTorch.

Translation code is based on Theano.

Implementation of Gumbel-Gate LSTM: [Pytorch version](language-modeling/g2_lstm.py), [Theano version](machine-translation/libs/layers/stochastic_lstm.py).
